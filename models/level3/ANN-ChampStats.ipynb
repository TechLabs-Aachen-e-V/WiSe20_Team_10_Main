{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "motivated-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "played-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/processed/LOLOracleData_ChampStats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "persistent-mailman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTop</th>\n",
       "      <th>BTopWr</th>\n",
       "      <th>BToptags</th>\n",
       "      <th>BTophp</th>\n",
       "      <th>BTophpperlevel</th>\n",
       "      <th>BTopmovespeed</th>\n",
       "      <th>BToparmor</th>\n",
       "      <th>BToparmorperlevel</th>\n",
       "      <th>BTopspellblock</th>\n",
       "      <th>BTopspellblockperlevel</th>\n",
       "      <th>...</th>\n",
       "      <th>RSupspellblock</th>\n",
       "      <th>RSupspellblockperlevel</th>\n",
       "      <th>RSupattackrange</th>\n",
       "      <th>RSuphpregen</th>\n",
       "      <th>RSuphpregenperlevel</th>\n",
       "      <th>RSupattackdamage</th>\n",
       "      <th>RSupattackdamageperlevel</th>\n",
       "      <th>RSupattackspeedperlevel</th>\n",
       "      <th>RSupattackspeed</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camille</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>85</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>525</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>53.5440</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>2.300</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camille</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>85</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>525</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>54.9379</td>\n",
       "      <td>3.1416</td>\n",
       "      <td>1.360</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Irelia</td>\n",
       "      <td>0.513399</td>\n",
       "      <td>Diver</td>\n",
       "      <td>580.0</td>\n",
       "      <td>95</td>\n",
       "      <td>335</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>125</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>63.5400</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>2.125</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graves</td>\n",
       "      <td>0.511305</td>\n",
       "      <td>Specialist</td>\n",
       "      <td>555.0</td>\n",
       "      <td>92</td>\n",
       "      <td>340</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>150</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Camille</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>85</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>175</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>64.0000</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>2.950</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BTop    BTopWr    BToptags  BTophp  BTophpperlevel  BTopmovespeed  \\\n",
       "0  Camille  0.524364       Diver   575.6              85            340   \n",
       "1  Camille  0.524364       Diver   575.6              85            340   \n",
       "2   Irelia  0.513399       Diver   580.0              95            335   \n",
       "3   Graves  0.511305  Specialist   555.0              92            340   \n",
       "4  Camille  0.524364       Diver   575.6              85            340   \n",
       "\n",
       "   BToparmor  BToparmorperlevel  BTopspellblock  BTopspellblockperlevel  ...  \\\n",
       "0       35.0                3.8            32.1                    1.25  ...   \n",
       "1       35.0                3.8            32.1                    1.25  ...   \n",
       "2       36.0                3.0            32.0                    1.25  ...   \n",
       "3       33.0                3.4            32.0                    1.25  ...   \n",
       "4       35.0                3.8            32.1                    1.25  ...   \n",
       "\n",
       "   RSupspellblock  RSupspellblockperlevel  RSupattackrange  RSuphpregen  \\\n",
       "0            30.0                    0.50              525          5.5   \n",
       "1            30.0                    0.50              525          5.5   \n",
       "2            32.1                    1.25              125          5.0   \n",
       "3            32.0                    1.25              150          7.0   \n",
       "4            28.0                    1.25              175         10.0   \n",
       "\n",
       "   RSuphpregenperlevel  RSupattackdamage  RSupattackdamageperlevel  \\\n",
       "0                 0.55           53.5440                    3.3000   \n",
       "1                 0.55           54.9379                    3.1416   \n",
       "2                 0.75           63.5400                    3.3000   \n",
       "3                 0.50           62.0000                    2.0000   \n",
       "4                 0.65           64.0000                    3.3000   \n",
       "\n",
       "  RSupattackspeedperlevel  RSupattackspeed Winner  \n",
       "0                   2.300            0.625      1  \n",
       "1                   1.360            0.625      0  \n",
       "2                   2.125            0.800      0  \n",
       "3                   2.500            0.667      1  \n",
       "4                   2.950            0.644      1  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incorrect-packet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BTop', 'BTopWr', 'BToptags', 'BTophp', 'BTophpperlevel',\n",
      "       'BTopmovespeed', 'BToparmor', 'BToparmorperlevel', 'BTopspellblock',\n",
      "       'BTopspellblockperlevel',\n",
      "       ...\n",
      "       'RSupspellblock', 'RSupspellblockperlevel', 'RSupattackrange',\n",
      "       'RSuphpregen', 'RSuphpregenperlevel', 'RSupattackdamage',\n",
      "       'RSupattackdamageperlevel', 'RSupattackspeedperlevel',\n",
      "       'RSupattackspeed', 'Winner'],\n",
      "      dtype='object', length=171)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "documentary-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "Blue = ['BTophpperlevel','BToparmorperlevel','BTopspellblock',\n",
    " 'BTopspellblockperlevel','BTophpregenperlevel','BTopattackdamageperlevel','BTopattackspeedperlevel',\n",
    " 'BJnghpperlevel','BJngarmorperlevel','BJngspellblock',\n",
    " 'BJngspellblockperlevel','BJnghpregenperlevel','BJngattackdamageperlevel','BJngattackspeedperlevel',\n",
    " 'BMidhpperlevel','BMidarmorperlevel','BMidspellblock',\n",
    " 'BMidspellblockperlevel','BMidhpregenperlevel','BMidattackdamageperlevel','BMidattackspeedperlevel',\n",
    " 'BAdchpperlevel','BAdcarmorperlevel','BAdcspellblock',\n",
    " 'BAdcspellblockperlevel','BAdchpregenperlevel','BAdcattackdamageperlevel','BAdcattackspeedperlevel',\n",
    " 'BSuphpperlevel','BSuparmorperlevel','BSupspellblock',\n",
    " 'BSupspellblockperlevel','BSuphpregenperlevel','BSupattackdamageperlevel','BSupattackspeedperlevel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunrise-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "duplicate-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "Red = ['R'+blue[1:] for blue in Blue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "considerable-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "advisory-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(Blue,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "immediate-automation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTop</th>\n",
       "      <th>BTopWr</th>\n",
       "      <th>BToptags</th>\n",
       "      <th>BTophp</th>\n",
       "      <th>BTopmovespeed</th>\n",
       "      <th>BToparmor</th>\n",
       "      <th>BTopattackrange</th>\n",
       "      <th>BTophpregen</th>\n",
       "      <th>BTopattackdamage</th>\n",
       "      <th>BTopattackspeed</th>\n",
       "      <th>...</th>\n",
       "      <th>RSupspellblock</th>\n",
       "      <th>RSupspellblockperlevel</th>\n",
       "      <th>RSupattackrange</th>\n",
       "      <th>RSuphpregen</th>\n",
       "      <th>RSuphpregenperlevel</th>\n",
       "      <th>RSupattackdamage</th>\n",
       "      <th>RSupattackdamageperlevel</th>\n",
       "      <th>RSupattackspeedperlevel</th>\n",
       "      <th>RSupattackspeed</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camille</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.644</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>525</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>53.5440</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>2.300</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camille</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.644</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>525</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>54.9379</td>\n",
       "      <td>3.1416</td>\n",
       "      <td>1.360</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Irelia</td>\n",
       "      <td>0.513399</td>\n",
       "      <td>Diver</td>\n",
       "      <td>580.0</td>\n",
       "      <td>335</td>\n",
       "      <td>36.0</td>\n",
       "      <td>200</td>\n",
       "      <td>8.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.656</td>\n",
       "      <td>...</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>125</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>63.5400</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>2.125</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graves</td>\n",
       "      <td>0.511305</td>\n",
       "      <td>Specialist</td>\n",
       "      <td>555.0</td>\n",
       "      <td>340</td>\n",
       "      <td>33.0</td>\n",
       "      <td>425</td>\n",
       "      <td>8.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>150</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Camille</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.644</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>175</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>64.0000</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>2.950</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BTop    BTopWr    BToptags  BTophp  BTopmovespeed  BToparmor  \\\n",
       "0  Camille  0.524364       Diver   575.6            340       35.0   \n",
       "1  Camille  0.524364       Diver   575.6            340       35.0   \n",
       "2   Irelia  0.513399       Diver   580.0            335       36.0   \n",
       "3   Graves  0.511305  Specialist   555.0            340       33.0   \n",
       "4  Camille  0.524364       Diver   575.6            340       35.0   \n",
       "\n",
       "   BTopattackrange  BTophpregen  BTopattackdamage  BTopattackspeed  ...  \\\n",
       "0              125          8.5              68.0            0.644  ...   \n",
       "1              125          8.5              68.0            0.644  ...   \n",
       "2              200          8.5              65.0            0.656  ...   \n",
       "3              425          8.0              68.0            0.475  ...   \n",
       "4              125          8.5              68.0            0.644  ...   \n",
       "\n",
       "  RSupspellblock  RSupspellblockperlevel RSupattackrange  RSuphpregen  \\\n",
       "0           30.0                    0.50             525          5.5   \n",
       "1           30.0                    0.50             525          5.5   \n",
       "2           32.1                    1.25             125          5.0   \n",
       "3           32.0                    1.25             150          7.0   \n",
       "4           28.0                    1.25             175         10.0   \n",
       "\n",
       "   RSuphpregenperlevel  RSupattackdamage  RSupattackdamageperlevel  \\\n",
       "0                 0.55           53.5440                    3.3000   \n",
       "1                 0.55           54.9379                    3.1416   \n",
       "2                 0.75           63.5400                    3.3000   \n",
       "3                 0.50           62.0000                    2.0000   \n",
       "4                 0.65           64.0000                    3.3000   \n",
       "\n",
       "   RSupattackspeedperlevel  RSupattackspeed  Winner  \n",
       "0                    2.300            0.625       1  \n",
       "1                    1.360            0.625       0  \n",
       "2                    2.125            0.800       0  \n",
       "3                    2.500            0.667       1  \n",
       "4                    2.950            0.644       1  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "constant-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(Red,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "waiting-polish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTop</th>\n",
       "      <th>BTopWr</th>\n",
       "      <th>BToptags</th>\n",
       "      <th>BTophp</th>\n",
       "      <th>BTopmovespeed</th>\n",
       "      <th>BToparmor</th>\n",
       "      <th>BTopattackrange</th>\n",
       "      <th>BTophpregen</th>\n",
       "      <th>BTopattackdamage</th>\n",
       "      <th>BTopattackspeed</th>\n",
       "      <th>...</th>\n",
       "      <th>RSupWr</th>\n",
       "      <th>RSuptags</th>\n",
       "      <th>RSuphp</th>\n",
       "      <th>RSupmovespeed</th>\n",
       "      <th>RSuparmor</th>\n",
       "      <th>RSupattackrange</th>\n",
       "      <th>RSuphpregen</th>\n",
       "      <th>RSupattackdamage</th>\n",
       "      <th>RSupattackspeed</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Camille</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492260</td>\n",
       "      <td>Enchanter</td>\n",
       "      <td>534.0</td>\n",
       "      <td>335</td>\n",
       "      <td>26.00</td>\n",
       "      <td>525</td>\n",
       "      <td>5.5</td>\n",
       "      <td>53.5440</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camille</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>Artillery</td>\n",
       "      <td>520.0</td>\n",
       "      <td>340</td>\n",
       "      <td>21.88</td>\n",
       "      <td>525</td>\n",
       "      <td>5.5</td>\n",
       "      <td>54.9379</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Irelia</td>\n",
       "      <td>0.513399</td>\n",
       "      <td>Diver</td>\n",
       "      <td>580.0</td>\n",
       "      <td>335</td>\n",
       "      <td>36.0</td>\n",
       "      <td>200</td>\n",
       "      <td>8.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527418</td>\n",
       "      <td>Vanguard</td>\n",
       "      <td>565.0</td>\n",
       "      <td>335</td>\n",
       "      <td>39.00</td>\n",
       "      <td>125</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63.5400</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graves</td>\n",
       "      <td>0.511305</td>\n",
       "      <td>Specialist</td>\n",
       "      <td>555.0</td>\n",
       "      <td>340</td>\n",
       "      <td>33.0</td>\n",
       "      <td>425</td>\n",
       "      <td>8.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492582</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>600.0</td>\n",
       "      <td>330</td>\n",
       "      <td>45.00</td>\n",
       "      <td>150</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Camille</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473513</td>\n",
       "      <td>Diver</td>\n",
       "      <td>580.0</td>\n",
       "      <td>345</td>\n",
       "      <td>40.00</td>\n",
       "      <td>175</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0000</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BTop    BTopWr    BToptags  BTophp  BTopmovespeed  BToparmor  \\\n",
       "0  Camille  0.524364       Diver   575.6            340       35.0   \n",
       "1  Camille  0.524364       Diver   575.6            340       35.0   \n",
       "2   Irelia  0.513399       Diver   580.0            335       36.0   \n",
       "3   Graves  0.511305  Specialist   555.0            340       33.0   \n",
       "4  Camille  0.524364       Diver   575.6            340       35.0   \n",
       "\n",
       "   BTopattackrange  BTophpregen  BTopattackdamage  BTopattackspeed  ...  \\\n",
       "0              125          8.5              68.0            0.644  ...   \n",
       "1              125          8.5              68.0            0.644  ...   \n",
       "2              200          8.5              65.0            0.656  ...   \n",
       "3              425          8.0              68.0            0.475  ...   \n",
       "4              125          8.5              68.0            0.644  ...   \n",
       "\n",
       "     RSupWr   RSuptags RSuphp  RSupmovespeed  RSuparmor  RSupattackrange  \\\n",
       "0  0.492260  Enchanter  534.0            335      26.00              525   \n",
       "1  0.440678  Artillery  520.0            340      21.88              525   \n",
       "2  0.527418   Vanguard  565.0            335      39.00              125   \n",
       "3  0.492582   Assassin  600.0            330      45.00              150   \n",
       "4  0.473513      Diver  580.0            345      40.00              175   \n",
       "\n",
       "   RSuphpregen  RSupattackdamage  RSupattackspeed  Winner  \n",
       "0          5.5           53.5440            0.625       1  \n",
       "1          5.5           54.9379            0.625       0  \n",
       "2          5.0           63.5400            0.800       0  \n",
       "3          7.0           62.0000            0.667       1  \n",
       "4         10.0           64.0000            0.644       1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "white-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = ['BTop','BJng','BMid','BAdc','BSup','RTop','RJng','RMid','RAdc','RSup']\n",
    "df.drop(role,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "everyday-trash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTopWr</th>\n",
       "      <th>BToptags</th>\n",
       "      <th>BTophp</th>\n",
       "      <th>BTopmovespeed</th>\n",
       "      <th>BToparmor</th>\n",
       "      <th>BTopattackrange</th>\n",
       "      <th>BTophpregen</th>\n",
       "      <th>BTopattackdamage</th>\n",
       "      <th>BTopattackspeed</th>\n",
       "      <th>BJngWr</th>\n",
       "      <th>...</th>\n",
       "      <th>RSupWr</th>\n",
       "      <th>RSuptags</th>\n",
       "      <th>RSuphp</th>\n",
       "      <th>RSupmovespeed</th>\n",
       "      <th>RSuparmor</th>\n",
       "      <th>RSupattackrange</th>\n",
       "      <th>RSuphpregen</th>\n",
       "      <th>RSupattackdamage</th>\n",
       "      <th>RSupattackspeed</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.506967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492260</td>\n",
       "      <td>Enchanter</td>\n",
       "      <td>534.0</td>\n",
       "      <td>335</td>\n",
       "      <td>26.00</td>\n",
       "      <td>525</td>\n",
       "      <td>5.5</td>\n",
       "      <td>53.5440</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.504318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>Artillery</td>\n",
       "      <td>520.0</td>\n",
       "      <td>340</td>\n",
       "      <td>21.88</td>\n",
       "      <td>525</td>\n",
       "      <td>5.5</td>\n",
       "      <td>54.9379</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.513399</td>\n",
       "      <td>Diver</td>\n",
       "      <td>580.0</td>\n",
       "      <td>335</td>\n",
       "      <td>36.0</td>\n",
       "      <td>200</td>\n",
       "      <td>8.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.486450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527418</td>\n",
       "      <td>Vanguard</td>\n",
       "      <td>565.0</td>\n",
       "      <td>335</td>\n",
       "      <td>39.00</td>\n",
       "      <td>125</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63.5400</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511305</td>\n",
       "      <td>Specialist</td>\n",
       "      <td>555.0</td>\n",
       "      <td>340</td>\n",
       "      <td>33.0</td>\n",
       "      <td>425</td>\n",
       "      <td>8.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.505097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492582</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>600.0</td>\n",
       "      <td>330</td>\n",
       "      <td>45.00</td>\n",
       "      <td>150</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.524364</td>\n",
       "      <td>Diver</td>\n",
       "      <td>575.6</td>\n",
       "      <td>340</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125</td>\n",
       "      <td>8.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.509764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473513</td>\n",
       "      <td>Diver</td>\n",
       "      <td>580.0</td>\n",
       "      <td>345</td>\n",
       "      <td>40.00</td>\n",
       "      <td>175</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0000</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BTopWr    BToptags  BTophp  BTopmovespeed  BToparmor  BTopattackrange  \\\n",
       "0  0.524364       Diver   575.6            340       35.0              125   \n",
       "1  0.524364       Diver   575.6            340       35.0              125   \n",
       "2  0.513399       Diver   580.0            335       36.0              200   \n",
       "3  0.511305  Specialist   555.0            340       33.0              425   \n",
       "4  0.524364       Diver   575.6            340       35.0              125   \n",
       "\n",
       "   BTophpregen  BTopattackdamage  BTopattackspeed    BJngWr  ...    RSupWr  \\\n",
       "0          8.5              68.0            0.644  0.506967  ...  0.492260   \n",
       "1          8.5              68.0            0.644  0.504318  ...  0.440678   \n",
       "2          8.5              65.0            0.656  0.486450  ...  0.527418   \n",
       "3          8.0              68.0            0.475  0.505097  ...  0.492582   \n",
       "4          8.5              68.0            0.644  0.509764  ...  0.473513   \n",
       "\n",
       "    RSuptags  RSuphp  RSupmovespeed  RSuparmor  RSupattackrange  RSuphpregen  \\\n",
       "0  Enchanter   534.0            335      26.00              525          5.5   \n",
       "1  Artillery   520.0            340      21.88              525          5.5   \n",
       "2   Vanguard   565.0            335      39.00              125          5.0   \n",
       "3   Assassin   600.0            330      45.00              150          7.0   \n",
       "4      Diver   580.0            345      40.00              175         10.0   \n",
       "\n",
       "   RSupattackdamage  RSupattackspeed Winner  \n",
       "0           53.5440            0.625      1  \n",
       "1           54.9379            0.625      0  \n",
       "2           63.5400            0.800      0  \n",
       "3           62.0000            0.667      1  \n",
       "4           64.0000            0.644      1  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nuclear-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9920\n",
       "1    9759\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "listed-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['BToptags','BJngtags','BMidtags','BAdctags','BSuptags','RToptags','RJngtags','RMidtags','RAdctags','RSuptags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stable-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = list(df.columns)\n",
    "\n",
    "for i in cont_cols:\n",
    "    if i in cat_cols:\n",
    "        cont_cols.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "significant-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols.remove('Winner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "lasting-steering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "collaborative-money",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "greatest-excitement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "prospective-forum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BTopWr              float64\n",
       "BToptags             object\n",
       "BTophp              float64\n",
       "BTopmovespeed         int64\n",
       "BToparmor           float64\n",
       "                     ...   \n",
       "RSupattackrange       int64\n",
       "RSuphpregen         float64\n",
       "RSupattackdamage    float64\n",
       "RSupattackspeed     float64\n",
       "Winner                int64\n",
       "Length: 91, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "invisible-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "alone-median",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BTopWr               float64\n",
       "BToptags            category\n",
       "BTophp               float64\n",
       "BTopmovespeed          int64\n",
       "BToparmor            float64\n",
       "                      ...   \n",
       "RSupattackrange        int64\n",
       "RSuphpregen          float64\n",
       "RSupattackdamage     float64\n",
       "RSupattackspeed      float64\n",
       "Winner                 int64\n",
       "Length: 91, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "happy-passport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Diver\n",
       "1         Diver\n",
       "2         Diver\n",
       "3    Specialist\n",
       "4         Diver\n",
       "Name: BToptags, dtype: category\n",
       "Categories (13, object): ['Artillery', 'Assassin', 'Battlemage', 'Burst', ..., 'Skirmisher', 'Specialist', 'Vanguard', 'Warden']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BToptags'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "overhead-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Artillery', 'Assassin', 'Battlemage', 'Burst', 'Catcher', 'Diver',\n",
       "       'Enchanter', 'Juggernaut', 'Marksman', 'Skirmisher', 'Specialist',\n",
       "       'Vanguard', 'Warden'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BToptags'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "crucial-enhancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         5\n",
       "1         5\n",
       "2         5\n",
       "3        10\n",
       "4         5\n",
       "         ..\n",
       "19674     0\n",
       "19675     8\n",
       "19676     8\n",
       "19677     2\n",
       "19678     5\n",
       "Length: 19679, dtype: int8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BToptags'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "exotic-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "present-alignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 11,  9, ...,  3,  8,  6],\n",
       "       [ 5, 10, 12, ...,  0,  8,  0],\n",
       "       [ 5,  1,  3, ...,  3,  8, 11],\n",
       "       ...,\n",
       "       [ 8, 10,  5, ...,  8,  8, 12],\n",
       "       [ 2,  7,  3, ...,  2,  8,  4],\n",
       "       [ 5,  5,  3, ..., 12,  8,  4]], dtype=int8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "regional-throw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19679, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "classified-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = torch.tensor(cats, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "miniature-sudan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 11,  9,  ...,  3,  8,  6],\n",
       "        [ 5, 10, 12,  ...,  0,  8,  0],\n",
       "        [ 5,  1,  3,  ...,  3,  8, 11],\n",
       "        ...,\n",
       "        [ 8, 10,  5,  ...,  8,  8, 12],\n",
       "        [ 2,  7,  3,  ...,  2,  8,  4],\n",
       "        [ 5,  5,  3,  ..., 12,  8,  4]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "refined-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "conts = torch.tensor(conts, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "facial-version",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.2436e-01, 5.7560e+02, 3.4000e+02,  ..., 5.5000e+00, 5.3544e+01,\n",
       "         6.2500e-01],\n",
       "        [5.2436e-01, 5.7560e+02, 3.4000e+02,  ..., 5.5000e+00, 5.4938e+01,\n",
       "         6.2500e-01],\n",
       "        [5.1340e-01, 5.8000e+02, 3.3500e+02,  ..., 5.0000e+00, 6.3540e+01,\n",
       "         8.0000e-01],\n",
       "        ...,\n",
       "        [4.9311e-01, 5.5900e+02, 3.2500e+02,  ..., 8.5000e+00, 5.5376e+01,\n",
       "         6.4400e-01],\n",
       "        [4.7015e-01, 5.3700e+02, 3.3000e+02,  ..., 7.0000e+00, 5.6000e+01,\n",
       "         6.2500e-01],\n",
       "        [5.2436e-01, 5.7560e+02, 3.4000e+02,  ..., 5.0000e+00, 6.2000e+01,\n",
       "         6.3500e-01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "provincial-spread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19679, 80])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "junior-anime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "seventh-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = ['Winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "applied-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(df[y_col].values).flatten()\n",
    "\n",
    "#Note: the CrossEntropyLoss function expects a 1d y-tensor, so we end up using .flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "formed-ground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0,  ..., 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "narrative-dividend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19679, 10])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "basic-atlas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19679, 80])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "banned-replication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19679])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "banner-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (12, 6),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "unusual-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "coastal-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(emb_szs, conts.shape[1], 2, [300, 400, 350,240,200,160,140,120,130], p=0.4) # out_sz = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "earlier-title",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(13, 7)\n",
       "    (1): Embedding(13, 7)\n",
       "    (2): Embedding(13, 7)\n",
       "    (3): Embedding(13, 7)\n",
       "    (4): Embedding(13, 7)\n",
       "    (5): Embedding(13, 7)\n",
       "    (6): Embedding(12, 6)\n",
       "    (7): Embedding(13, 7)\n",
       "    (8): Embedding(13, 7)\n",
       "    (9): Embedding(13, 7)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=149, out_features=300, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=300, out_features=400, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=400, out_features=350, bias=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm1d(350, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.4, inplace=False)\n",
       "    (12): Linear(in_features=350, out_features=240, bias=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): Dropout(p=0.4, inplace=False)\n",
       "    (16): Linear(in_features=240, out_features=200, bias=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): Dropout(p=0.4, inplace=False)\n",
       "    (20): Linear(in_features=200, out_features=160, bias=True)\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): Dropout(p=0.4, inplace=False)\n",
       "    (24): Linear(in_features=160, out_features=140, bias=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): BatchNorm1d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): Dropout(p=0.4, inplace=False)\n",
       "    (28): Linear(in_features=140, out_features=120, bias=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (31): Dropout(p=0.4, inplace=False)\n",
       "    (32): Linear(in_features=120, out_features=130, bias=True)\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): BatchNorm1d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): Dropout(p=0.4, inplace=False)\n",
       "    (36): Linear(in_features=130, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "exciting-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "seven-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "test_size = 5000\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "phantom-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "enclosed-register",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "suffering-pittsburgh",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.69687033\n",
      "epoch:  26  loss: 0.69641423\n",
      "epoch:  51  loss: 0.69383472\n",
      "epoch:  76  loss: 0.69522208\n",
      "epoch: 101  loss: 0.69569945\n",
      "epoch: 126  loss: 0.69283485\n",
      "epoch: 151  loss: 0.69290656\n",
      "epoch: 176  loss: 0.69304121\n",
      "epoch: 201  loss: 0.69210136\n",
      "epoch: 226  loss: 0.69215494\n",
      "epoch: 250  loss: 0.69090968\n",
      "\n",
      "Duration: 101 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 250\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 0:\n",
    "        print(f'epoch: {i+1:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i+1:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "advance-roads",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "successful-return",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.69324577\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "social-coach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT               ARGMAX  Y_TEST\n",
      "tensor([-0.1598, -0.0553])    1      0   \n",
      "tensor([0.5231, 0.4631])      0      1   \n",
      "tensor([0.8051, 0.7683])      0      1   \n",
      "tensor([-0.2344, -0.3166])    0      1   \n",
      "tensor([-0.4788, -0.5343])    0      1   \n",
      "tensor([-0.1386,  0.1445])    1      0   \n",
      "tensor([-0.3393, -0.5205])    0      0   \n",
      "tensor([-1.0562, -0.9465])    1      1   \n",
      "tensor([-0.1179, -0.2499])    0      1   \n",
      "tensor([ 0.0052, -0.1102])    0      1   \n",
      "tensor([0.6718, 0.7749])      1      0   \n",
      "tensor([-0.1983, -0.3781])    0      1   \n",
      "tensor([0.7433, 0.7301])      0      0   \n",
      "tensor([0.8364, 0.7954])      0      0   \n",
      "tensor([-1.2260, -1.2426])    0      1   \n",
      "tensor([-0.1222, -0.2026])    0      0   \n",
      "tensor([0.3430, 0.3367])      0      1   \n",
      "tensor([0.1350, 0.0744])      0      1   \n",
      "tensor([-0.0483,  0.1144])    1      1   \n",
      "tensor([-0.7249, -0.6064])    1      1   \n",
      "tensor([0.4541, 0.4416])      0      1   \n",
      "tensor([-0.0318, -0.2365])    0      1   \n",
      "tensor([-1.4867, -1.4426])    1      0   \n",
      "tensor([-0.1798, -0.1968])    0      0   \n",
      "tensor([-0.2820, -0.4165])    0      0   \n",
      "tensor([0.4740, 0.4795])      1      1   \n",
      "tensor([0.6178, 0.4777])      0      1   \n",
      "tensor([ 0.1806, -0.0323])    0      0   \n",
      "tensor([-0.2730, -0.4367])    0      0   \n",
      "tensor([-0.1060, -0.1436])    0      0   \n",
      "tensor([0.1175, 0.0309])      0      0   \n",
      "tensor([-0.3633, -0.3832])    0      1   \n",
      "tensor([0.2508, 0.2902])      1      1   \n",
      "tensor([-0.0025,  0.0262])    1      0   \n",
      "tensor([-0.1502, -0.1700])    0      0   \n",
      "tensor([0.1136, 0.1792])      1      1   \n",
      "tensor([-0.1307, -0.2026])    0      0   \n",
      "tensor([0.3636, 0.1676])      0      0   \n",
      "tensor([-0.1257,  0.0721])    1      1   \n",
      "tensor([ 0.0645, -0.0137])    0      0   \n",
      "tensor([-0.6857, -0.6975])    0      1   \n",
      "tensor([0.7997, 1.9688])      1      0   \n",
      "tensor([-0.3692, -0.2276])    1      0   \n",
      "tensor([0.3561, 0.3764])      1      1   \n",
      "tensor([-0.5642, -0.6042])    0      0   \n",
      "tensor([-0.2076, -0.2229])    0      0   \n",
      "tensor([0.9866, 0.9579])      0      1   \n",
      "tensor([ 0.1090, -0.0708])    0      1   \n",
      "tensor([-1.0372, -0.9433])    1      1   \n",
      "tensor([-0.0822, -0.2199])    0      0   \n",
      "tensor([0.4549, 0.3891])      0      0   \n",
      "tensor([-0.0657, -0.1818])    0      1   \n",
      "tensor([0.2147, 0.1141])      0      0   \n",
      "tensor([-0.0806, -0.1697])    0      0   \n",
      "tensor([-1.3891, -1.5769])    0      0   \n",
      "tensor([0.0090, 0.0014])      0      0   \n",
      "tensor([-0.6932, -0.7318])    0      0   \n",
      "tensor([0.9330, 0.8646])      0      0   \n",
      "tensor([-0.3506, -0.2565])    1      1   \n",
      "tensor([-0.0790, -0.0759])    1      1   \n",
      "tensor([-0.0121, -0.1176])    0      0   \n",
      "tensor([0.8218, 0.7828])      0      0   \n",
      "tensor([0.4201, 0.4550])      1      0   \n",
      "tensor([ 0.0833, -0.0038])    0      0   \n",
      "tensor([-0.2127, -0.0693])    1      1   \n",
      "tensor([0.5860, 0.5107])      0      0   \n",
      "tensor([-0.3553, -0.4310])    0      1   \n",
      "tensor([-0.4432, -0.3943])    1      0   \n",
      "tensor([-1.6799, -1.6960])    0      1   \n",
      "tensor([0.4198, 0.4418])      1      1   \n",
      "tensor([0.5620, 0.5361])      0      1   \n",
      "tensor([0.2474, 0.1806])      0      1   \n",
      "tensor([1.4758, 1.6230])      1      1   \n",
      "tensor([-0.7244, -0.7257])    0      0   \n",
      "tensor([-0.0143, -0.1516])    0      0   \n",
      "tensor([0.2504, 0.2058])      0      1   \n",
      "tensor([0.8903, 0.8706])      0      0   \n",
      "tensor([0.6301, 0.5534])      0      0   \n",
      "tensor([0.2454, 0.0785])      0      0   \n",
      "tensor([-0.0497, -0.1862])    0      0   \n",
      "tensor([0.0922, 0.0438])      0      0   \n",
      "tensor([-0.2058, -0.1774])    1      0   \n",
      "tensor([0.2811, 0.1301])      0      1   \n",
      "tensor([0.0532, 0.1415])      1      1   \n",
      "tensor([0.0608, 0.0754])      1      1   \n",
      "tensor([-0.3264, -0.3316])    0      1   \n",
      "tensor([0.3253, 0.2793])      0      1   \n",
      "tensor([0.4016, 0.1861])      0      1   \n",
      "tensor([0.2582, 0.2222])      0      0   \n",
      "tensor([0.3975, 0.3146])      0      1   \n",
      "tensor([-0.2936,  0.1377])    1      1   \n",
      "tensor([0.4764, 0.3523])      0      1   \n",
      "tensor([-0.2331, -0.2993])    0      0   \n",
      "tensor([0.5468, 0.4855])      0      0   \n",
      "tensor([-0.1473, -0.2902])    0      0   \n",
      "tensor([-0.3492, -0.2619])    1      1   \n",
      "tensor([-0.5314, -0.6932])    0      1   \n",
      "tensor([-0.5807, -0.7090])    0      1   \n",
      "tensor([-0.0627, -0.1354])    0      1   \n",
      "tensor([ 0.0681, -0.1141])    0      1   \n",
      "tensor([-0.2386, -0.3089])    0      0   \n",
      "tensor([0.2557, 0.2774])      1      1   \n",
      "tensor([0.2373, 0.1674])      0      1   \n",
      "tensor([-0.1868, -0.2558])    0      0   \n",
      "tensor([0.0065, 0.5216])      1      0   \n",
      "tensor([-0.0660, -0.2112])    0      1   \n",
      "tensor([ 0.0762, -0.0419])    0      1   \n",
      "tensor([ 0.0532, -0.1031])    0      0   \n",
      "tensor([-0.9060, -0.8311])    1      0   \n",
      "tensor([-0.6434, -0.6625])    0      1   \n",
      "tensor([-0.2569, -0.3208])    0      1   \n",
      "tensor([0.4126, 0.2848])      0      0   \n",
      "tensor([0.2192, 0.0372])      0      0   \n",
      "tensor([-0.0484, -0.0990])    0      1   \n",
      "tensor([-0.6818, -0.8369])    0      1   \n",
      "tensor([-0.5275, -0.5952])    0      0   \n",
      "tensor([-1.1919, -0.9352])    1      0   \n",
      "tensor([-0.4678, -0.3247])    1      1   \n",
      "tensor([0.3981, 0.2637])      0      1   \n",
      "tensor([0.3017, 0.2750])      0      1   \n",
      "tensor([0.6858, 0.6532])      0      0   \n",
      "tensor([-0.0346, -0.1305])    0      1   \n",
      "tensor([0.4788, 0.3490])      0      0   \n",
      "tensor([-0.6197, -0.6816])    0      0   \n",
      "tensor([-0.9304, -0.9121])    1      1   \n",
      "tensor([-0.3721, -0.3843])    0      1   \n",
      "tensor([-0.2293, -0.2586])    0      0   \n",
      "tensor([ 0.0863, -0.0814])    0      0   \n",
      "tensor([0.0378, 0.0303])      0      0   \n",
      "tensor([0.3385, 0.2963])      0      1   \n",
      "tensor([-1.0769, -1.0056])    1      1   \n",
      "tensor([-0.2458, -0.2947])    0      0   \n",
      "tensor([-0.4837, -0.6128])    0      1   \n",
      "tensor([-0.1876, -0.2702])    0      1   \n",
      "tensor([-0.4740, -0.5136])    0      0   \n",
      "tensor([-0.5318, -0.5854])    0      1   \n",
      "tensor([-0.4875, -0.5313])    0      0   \n",
      "tensor([-0.8238, -0.8793])    0      1   \n",
      "tensor([0.0082, 0.0065])      0      1   \n",
      "tensor([0.6046, 0.4455])      0      1   \n",
      "tensor([ 0.0469, -0.1519])    0      1   \n",
      "tensor([ 0.0226, -0.0590])    0      1   \n",
      "tensor([0.8961, 1.0530])      1      1   \n",
      "tensor([-0.4456, -0.4760])    0      1   \n",
      "tensor([0.1336, 0.0997])      0      1   \n",
      "tensor([ 0.0434, -0.0823])    0      0   \n",
      "tensor([0.0875, 0.0986])      1      0   \n",
      "tensor([-0.3263, -0.4117])    0      0   \n",
      "tensor([-0.3878, -0.1680])    1      0   \n",
      "tensor([0.9328, 1.0332])      1      0   \n",
      "tensor([1.2483, 1.0895])      0      0   \n",
      "tensor([0.3557, 0.3611])      1      1   \n",
      "tensor([0.5913, 0.4452])      0      0   \n",
      "tensor([0.4126, 0.4273])      1      1   \n",
      "tensor([-0.0915, -0.0559])    1      0   \n",
      "tensor([0.2776, 0.1848])      0      0   \n",
      "tensor([0.3241, 0.3173])      0      0   \n",
      "tensor([-0.4026, -0.4553])    0      1   \n",
      "tensor([0.1975, 0.0660])      0      0   \n",
      "tensor([0.6713, 0.5640])      0      0   \n",
      "tensor([0.4467, 0.4569])      1      0   \n",
      "tensor([-0.1802, -0.2457])    0      0   \n",
      "tensor([-0.5193, -0.6009])    0      0   \n",
      "tensor([0.5571, 0.4246])      0      1   \n",
      "tensor([0.6630, 0.6421])      0      1   \n",
      "tensor([0.3336, 0.2092])      0      0   \n",
      "tensor([0.5744, 0.5683])      0      1   \n",
      "tensor([-0.2606, -0.1254])    1      0   \n",
      "tensor([0.4086, 0.2228])      0      0   \n",
      "tensor([-0.6933, -0.4237])    1      1   \n",
      "tensor([-0.0795, -0.2012])    0      1   \n",
      "tensor([0.3632, 0.2972])      0      0   \n",
      "tensor([0.0947, 0.2578])      1      1   \n",
      "tensor([-0.7684, -0.8734])    0      0   \n",
      "tensor([0.6314, 0.4552])      0      0   \n",
      "tensor([0.4422, 0.2761])      0      1   \n",
      "tensor([0.8336, 0.9544])      1      1   \n",
      "tensor([0.8122, 0.7905])      0      0   \n",
      "tensor([-0.1867, -0.2666])    0      1   \n",
      "tensor([0.7675, 0.6937])      0      1   \n",
      "tensor([0.3111, 0.2139])      0      1   \n",
      "tensor([-0.3282, -0.3533])    0      1   \n",
      "tensor([-1.6498, -1.4286])    1      1   \n",
      "tensor([-0.7040, -0.8469])    0      1   \n",
      "tensor([0.2136, 0.2291])      1      0   \n",
      "tensor([-0.6407, -0.6382])    1      0   \n",
      "tensor([-0.2483, -0.2677])    0      1   \n",
      "tensor([-0.4812, -0.4886])    0      1   \n",
      "tensor([-0.4241, -0.4706])    0      0   \n",
      "tensor([-0.0811, -0.0934])    0      0   \n",
      "tensor([-1.7372, -1.9588])    0      0   \n",
      "tensor([-0.6890, -0.7502])    0      0   \n",
      "tensor([-0.3162, -0.4880])    0      1   \n",
      "tensor([-0.8171, -0.8820])    0      1   \n",
      "tensor([0.0241, 0.0441])      1      0   \n",
      "tensor([-0.3345, -0.2578])    1      1   \n",
      "tensor([0.4949, 0.4526])      0      0   \n",
      "tensor([-0.7960, -0.9853])    0      1   \n",
      "tensor([0.1844, 0.0991])      0      0   \n",
      "tensor([-0.4771,  0.1529])    1      0   \n",
      "tensor([0.2753, 0.1805])      0      1   \n",
      "tensor([-0.0122, -0.1811])    0      0   \n",
      "tensor([-0.1049, -0.1739])    0      0   \n",
      "tensor([0.1063, 0.4412])      1      1   \n",
      "tensor([0.1229, 0.1517])      1      0   \n",
      "tensor([-0.5377, -0.6543])    0      1   \n",
      "tensor([-0.1900, -0.1033])    1      0   \n",
      "tensor([-0.2034, -0.3775])    0      0   \n",
      "tensor([0.0695, 0.0556])      0      0   \n",
      "tensor([0.1007, 0.1476])      1      0   \n",
      "tensor([-0.5665, -0.5793])    0      0   \n",
      "tensor([0.3858, 0.2807])      0      1   \n",
      "tensor([0.7926, 0.6502])      0      1   \n",
      "tensor([0.7196, 0.6118])      0      0   \n",
      "tensor([ 0.0032, -0.1316])    0      0   \n",
      "tensor([-0.6213, -0.7768])    0      0   \n",
      "tensor([-0.1423, -0.1610])    0      1   \n",
      "tensor([-0.5002, -0.5705])    0      0   \n",
      "tensor([-0.0955, -0.1325])    0      0   \n",
      "tensor([0.0418, 0.0603])      1      0   \n",
      "tensor([0.2884, 0.1182])      0      1   \n",
      "tensor([-2.3579, -1.7793])    1      1   \n",
      "tensor([0.3893, 0.3141])      0      1   \n",
      "tensor([0.3370, 0.2300])      0      1   \n",
      "tensor([0.2281, 0.4675])      1      1   \n",
      "tensor([0.4077, 0.2539])      0      0   \n",
      "tensor([-0.2134, -0.4085])    0      0   \n",
      "tensor([ 0.0277, -0.1057])    0      0   \n",
      "tensor([-0.4255,  0.0583])    1      1   \n",
      "tensor([0.1033, 0.0955])      0      1   \n",
      "tensor([-0.2804, -0.3923])    0      1   \n",
      "tensor([-0.3721, -0.4229])    0      0   \n",
      "tensor([-0.3896, -0.5032])    0      1   \n",
      "tensor([0.6897, 0.6233])      0      1   \n",
      "tensor([-0.5079, -0.3953])    1      1   \n",
      "tensor([0.2331, 0.2100])      0      1   \n",
      "tensor([-0.3697, -0.3018])    1      0   \n",
      "tensor([0.2925, 0.2813])      0      0   \n",
      "tensor([-0.2470, -0.3346])    0      0   \n",
      "tensor([-0.5626, -0.5467])    1      1   \n",
      "tensor([0.2360, 0.1938])      0      0   \n",
      "tensor([0.3005, 0.2367])      0      0   \n",
      "tensor([-0.2792, -0.4380])    0      1   \n",
      "tensor([-0.2464,  0.1844])    1      0   \n",
      "tensor([-0.0840, -0.2001])    0      0   \n",
      "tensor([-0.1667, -0.2207])    0      0   \n",
      "tensor([0.5992, 0.5306])      0      0   \n",
      "tensor([-1.0335, -1.0322])    1      1   \n",
      "tensor([0.8907, 0.8231])      0      0   \n",
      "tensor([-0.7063, -0.8601])    0      1   \n",
      "tensor([0.4229, 0.3296])      0      1   \n",
      "tensor([-0.0414, -0.1344])    0      0   \n",
      "tensor([-0.3186, -0.4996])    0      0   \n",
      "tensor([0.1806, 0.1070])      0      1   \n",
      "tensor([0.3803, 0.4319])      1      1   \n",
      "tensor([-0.8864, -0.9515])    0      1   \n",
      "tensor([-1.0039, -0.9785])    1      1   \n",
      "tensor([-0.2162, -0.3053])    0      0   \n",
      "tensor([0.1193, 0.0490])      0      1   \n",
      "tensor([-0.6132, -0.6816])    0      1   \n",
      "tensor([0.3302, 0.1496])      0      0   \n",
      "tensor([-0.4159, -0.4933])    0      1   \n",
      "tensor([0.3004, 0.0906])      0      0   \n",
      "tensor([-1.5182, -1.2669])    1      1   \n",
      "tensor([0.1804, 0.1322])      0      0   \n",
      "tensor([-0.3114, -0.3211])    0      0   \n",
      "tensor([0.5001, 0.4026])      0      0   \n",
      "tensor([-0.4545, -0.5641])    0      1   \n",
      "tensor([0.1815, 0.1646])      0      1   \n",
      "tensor([0.3566, 0.5371])      1      1   \n",
      "tensor([-0.0204, -0.0489])    0      0   \n",
      "tensor([0.3455, 0.2438])      0      1   \n",
      "tensor([-0.2471, -0.3429])    0      0   \n",
      "tensor([-1.3677, -1.2891])    1      1   \n",
      "tensor([-0.7468, -0.7492])    0      1   \n",
      "tensor([-0.5366, -0.7061])    0      1   \n",
      "tensor([-0.5024, -0.5423])    0      0   \n",
      "tensor([0.0853, 0.0437])      0      1   \n",
      "tensor([0.4699, 0.4716])      1      0   \n",
      "tensor([-0.2898, -0.2293])    1      0   \n",
      "tensor([ 0.0128, -0.0671])    0      1   \n",
      "tensor([-0.0008, -0.0765])    0      1   \n",
      "tensor([-0.6401, -0.6306])    1      1   \n",
      "tensor([-0.2677, -0.4103])    0      0   \n",
      "tensor([-1.0232, -0.8216])    1      1   \n",
      "tensor([-0.8538, -0.6575])    1      1   \n",
      "tensor([-0.7491, -0.7328])    1      0   \n",
      "tensor([0.2226, 0.0847])      0      0   \n",
      "tensor([0.2095, 0.2200])      1      0   \n",
      "tensor([1.2854, 1.3488])      1      1   \n",
      "tensor([-0.6260, -0.4067])    1      1   \n",
      "tensor([-0.1952, -0.2202])    0      0   \n",
      "tensor([ 0.0134, -0.0581])    0      1   \n",
      "tensor([0.5400, 0.4433])      0      1   \n",
      "tensor([0.5280, 0.4543])      0      0   \n",
      "tensor([0.6620, 0.5237])      0      0   \n",
      "tensor([-0.4665, -0.5527])    0      0   \n",
      "tensor([0.1093, 0.0023])      0      1   \n",
      "tensor([-0.7926, -0.5750])    1      1   \n",
      "tensor([ 0.1007, -0.0644])    0      1   \n",
      "tensor([0.2356, 0.1887])      0      1   \n",
      "tensor([-0.2807, -0.3572])    0      0   \n",
      "tensor([ 0.1347, -0.0308])    0      0   \n",
      "tensor([-0.2572, -0.4073])    0      1   \n",
      "tensor([0.7302, 0.8670])      1      1   \n",
      "tensor([-0.2955, -0.3935])    0      1   \n",
      "tensor([0.5071, 0.2864])      0      0   \n",
      "tensor([0.9233, 1.0131])      1      1   \n",
      "tensor([-1.5455, -1.6505])    0      1   \n",
      "tensor([0.4144, 0.6598])      1      1   \n",
      "tensor([0.4967, 0.4403])      0      0   \n",
      "tensor([-0.3794, -0.4861])    0      0   \n",
      "tensor([0.7165, 0.8176])      1      1   \n",
      "tensor([0.8385, 1.0579])      1      1   \n",
      "tensor([1.3294, 1.3112])      0      1   \n",
      "tensor([0.1777, 0.0757])      0      1   \n",
      "tensor([-0.6552, -0.7684])    0      0   \n",
      "tensor([0.3287, 0.3259])      0      1   \n",
      "tensor([-0.1518, -0.2655])    0      0   \n",
      "tensor([-0.6512, -0.6757])    0      1   \n",
      "tensor([-0.4106, -0.4198])    0      1   \n",
      "tensor([ 0.0176, -0.0757])    0      0   \n",
      "tensor([0.3765, 0.2741])      0      0   \n",
      "tensor([-0.4515, -0.5724])    0      1   \n",
      "tensor([-0.5477, -0.5491])    0      0   \n",
      "tensor([ 0.1642, -0.0040])    0      1   \n",
      "tensor([-0.3084, -0.4089])    0      0   \n",
      "tensor([0.2685, 0.1318])      0      1   \n",
      "tensor([-0.0935, -0.1485])    0      1   \n",
      "tensor([-0.4840, -0.4531])    1      1   \n",
      "tensor([-0.9419, -0.8581])    1      0   \n",
      "tensor([0.1373, 0.0224])      0      0   \n",
      "tensor([0.1566, 0.2728])      1      1   \n",
      "tensor([0.3800, 0.2746])      0      1   \n",
      "tensor([1.3248, 1.2457])      0      0   \n",
      "tensor([0.3124, 0.2015])      0      0   \n",
      "tensor([0.5057, 0.4414])      0      1   \n",
      "tensor([-0.0425, -0.1335])    0      1   \n",
      "tensor([-0.1793, -0.3567])    0      0   \n",
      "tensor([-0.0173,  0.2461])    1      0   \n",
      "tensor([-0.4158, -0.5086])    0      1   \n",
      "tensor([-0.2633, -0.3511])    0      1   \n",
      "tensor([-0.2542, -0.2848])    0      1   \n",
      "tensor([ 0.1374, -0.0008])    0      0   \n",
      "tensor([0.6129, 0.3971])      0      1   \n",
      "tensor([0.2001, 0.1863])      0      1   \n",
      "tensor([-0.5114, -0.5627])    0      0   \n",
      "tensor([-0.2028, -0.0809])    1      1   \n",
      "tensor([0.1663, 0.2003])      1      1   \n",
      "tensor([0.1409, 0.0431])      0      0   \n",
      "tensor([0.5276, 0.6345])      1      0   \n",
      "tensor([-0.1375, -0.0479])    1      0   \n",
      "tensor([0.2228, 0.0775])      0      1   \n",
      "tensor([-0.8934, -0.9752])    0      1   \n",
      "tensor([-0.4072, -0.4223])    0      0   \n",
      "tensor([-0.1513, -0.1527])    0      1   \n",
      "tensor([-0.1119, -0.2221])    0      0   \n",
      "tensor([-0.1237, -0.2571])    0      0   \n",
      "tensor([-0.8022, -0.9252])    0      0   \n",
      "tensor([0.3057, 0.1724])      0      1   \n",
      "tensor([0.3235, 0.0838])      0      0   \n",
      "tensor([0.2336, 0.1848])      0      0   \n",
      "tensor([-0.0429, -0.0404])    1      1   \n",
      "tensor([-0.3348, -0.4160])    0      0   \n",
      "tensor([-0.1431, -0.3959])    0      0   \n",
      "tensor([-0.2831, -0.2945])    0      1   \n",
      "tensor([0.1592, 0.0069])      0      1   \n",
      "tensor([ 0.0670, -0.0970])    0      0   \n",
      "tensor([0.0711, 0.2228])      1      1   \n",
      "tensor([-0.2109, -0.1534])    1      1   \n",
      "tensor([-0.9731, -0.8238])    1      1   \n",
      "tensor([0.1157, 0.1647])      1      1   \n",
      "tensor([0.2666, 0.1572])      0      0   \n",
      "tensor([0.2925, 0.1480])      0      0   \n",
      "tensor([0.0557, 0.1106])      1      1   \n",
      "tensor([-0.5316, -0.4951])    1      0   \n",
      "tensor([-0.0620, -0.1430])    0      1   \n",
      "tensor([0.8633, 0.7593])      0      0   \n",
      "tensor([-0.3348, -0.3069])    1      0   \n",
      "tensor([0.2460, 0.1356])      0      1   \n",
      "tensor([0.9811, 1.2844])      1      0   \n",
      "tensor([-0.3744, -0.3105])    1      0   \n",
      "tensor([ 0.0245, -0.0856])    0      0   \n",
      "tensor([-0.4798, -0.3749])    1      1   \n",
      "tensor([0.1967, 0.2125])      1      0   \n",
      "tensor([-0.5678, -0.4823])    1      0   \n",
      "tensor([-0.7989, -0.9161])    0      0   \n",
      "tensor([0.5188, 0.3421])      0      1   \n",
      "tensor([0.3793, 0.2850])      0      1   \n",
      "tensor([-0.8301, -0.8632])    0      0   \n",
      "tensor([ 0.1369, -0.0729])    0      1   \n",
      "tensor([0.5493, 0.5009])      0      0   \n",
      "tensor([-0.3026, -0.2444])    1      0   \n",
      "tensor([0.4741, 0.4003])      0      1   \n",
      "tensor([-0.1292, -0.1440])    0      0   \n",
      "tensor([ 0.0017, -0.1047])    0      1   \n",
      "tensor([0.5142, 0.5401])      1      0   \n",
      "tensor([-0.8221, -0.8552])    0      1   \n",
      "tensor([0.2396, 0.1349])      0      0   \n",
      "tensor([-0.3555, -0.4455])    0      0   \n",
      "tensor([-0.3449, -0.3451])    0      0   \n",
      "tensor([-0.2256, -0.2499])    0      1   \n",
      "tensor([0.1686, 0.1577])      0      0   \n",
      "tensor([0.5024, 0.4779])      0      0   \n",
      "tensor([0.7992, 0.7380])      0      0   \n",
      "tensor([0.1964, 0.1048])      0      0   \n",
      "tensor([0.4380, 0.3510])      0      1   \n",
      "tensor([-0.2910, -0.2282])    1      1   \n",
      "tensor([0.5595, 0.3517])      0      1   \n",
      "tensor([1.1837, 1.3879])      1      0   \n",
      "tensor([-0.2566, -0.1363])    1      0   \n",
      "tensor([0.3353, 0.2848])      0      1   \n",
      "tensor([-0.1342, -0.2510])    0      0   \n",
      "tensor([0.4715, 0.2789])      0      0   \n",
      "tensor([1.2994, 1.7983])      1      0   \n",
      "tensor([-0.3168, -0.3359])    0      0   \n",
      "tensor([-0.1544, -0.0971])    1      1   \n",
      "tensor([-0.1391, -0.2319])    0      1   \n",
      "tensor([-0.0345, -0.1609])    0      1   \n",
      "tensor([-0.1274, -0.2359])    0      0   \n",
      "tensor([-0.8500, -0.6607])    1      1   \n",
      "tensor([-0.1277, -0.1718])    0      0   \n",
      "tensor([0.7598, 0.7148])      0      0   \n",
      "tensor([0.5070, 0.4366])      0      1   \n",
      "tensor([0.2570, 0.1193])      0      1   \n",
      "tensor([0.1578, 0.0475])      0      0   \n",
      "tensor([-0.4309, -0.5414])    0      0   \n",
      "tensor([-0.0721, -0.1424])    0      1   \n",
      "tensor([-0.6294, -0.7595])    0      1   \n",
      "tensor([0.3124, 0.4171])      1      0   \n",
      "tensor([0.4335, 0.2424])      0      1   \n",
      "tensor([0.4991, 0.4071])      0      0   \n",
      "tensor([-0.5625, -0.5205])    1      0   \n",
      "tensor([-0.2714, -0.3673])    0      1   \n",
      "tensor([0.5709, 0.4444])      0      1   \n",
      "tensor([0.3043, 0.3100])      1      1   \n",
      "tensor([-0.4478, -0.2641])    1      0   \n",
      "tensor([-0.8937, -0.9605])    0      1   \n",
      "tensor([-0.3192, -0.3279])    0      1   \n",
      "tensor([-0.0263, -0.1996])    0      0   \n",
      "tensor([-0.0032, -0.0084])    0      1   \n",
      "tensor([0.6739, 0.5050])      0      0   \n",
      "tensor([ 0.0628, -0.0363])    0      0   \n",
      "tensor([0.5302, 0.6498])      1      0   \n",
      "tensor([-0.2567, -0.2479])    1      0   \n",
      "tensor([0.3426, 0.5513])      1      0   \n",
      "tensor([-1.0467, -0.6185])    1      1   \n",
      "tensor([-0.4544, -0.5705])    0      0   \n",
      "tensor([0.2924, 0.1683])      0      0   \n",
      "tensor([-0.6388, -0.5014])    1      0   \n",
      "tensor([-0.2483, -0.3456])    0      1   \n",
      "tensor([0.3309, 0.2635])      0      1   \n",
      "tensor([-0.0459, -0.1293])    0      1   \n",
      "tensor([-0.3683, -0.3506])    1      1   \n",
      "tensor([0.5843, 0.8333])      1      0   \n",
      "tensor([-0.1458, -0.2709])    0      0   \n",
      "tensor([-0.8657, -0.9133])    0      1   \n",
      "tensor([0.2502, 0.2891])      1      0   \n",
      "tensor([0.2519, 0.0828])      0      1   \n",
      "tensor([-0.5824, -0.6136])    0      1   \n",
      "tensor([0.2497, 0.1715])      0      0   \n",
      "tensor([0.2577, 0.2211])      0      1   \n",
      "tensor([-0.2324, -0.3493])    0      0   \n",
      "tensor([0.5605, 0.4223])      0      0   \n",
      "tensor([0.1930, 0.0879])      0      1   \n",
      "tensor([-0.7892, -0.8982])    0      0   \n",
      "tensor([-0.3343, -0.4674])    0      1   \n",
      "tensor([-0.4526, -0.3905])    1      0   \n",
      "tensor([0.1963, 0.0924])      0      1   \n",
      "tensor([-1.8679, -1.6901])    1      0   \n",
      "tensor([-0.0828,  0.0536])    1      1   \n",
      "tensor([-0.8308, -0.6608])    1      1   \n",
      "tensor([0.2191, 0.0475])      0      0   \n",
      "tensor([-0.0040, -0.0505])    0      0   \n",
      "tensor([0.6551, 0.4614])      0      1   \n",
      "tensor([0.9944, 1.2423])      1      1   \n",
      "tensor([0.6558, 0.8891])      1      0   \n",
      "tensor([-0.4725, -0.4706])    1      0   \n",
      "tensor([0.4940, 0.3018])      0      1   \n",
      "tensor([0.1896, 0.1042])      0      1   \n",
      "tensor([-0.3804, -0.4532])    0      0   \n",
      "tensor([ 0.0780, -0.1142])    0      0   \n",
      "tensor([0.2516, 0.1593])      0      0   \n",
      "tensor([0.8005, 0.7836])      0      0   \n",
      "tensor([-0.2368, -0.3763])    0      1   \n",
      "tensor([-0.8427, -0.8932])    0      1   \n",
      "tensor([0.2179, 0.1713])      0      0   \n",
      "tensor([1.0450, 1.0580])      1      0   \n",
      "tensor([0.6268, 0.5711])      0      0   \n",
      "tensor([-0.4479, -0.5237])    0      1   \n",
      "tensor([0.1328, 0.1889])      1      1   \n",
      "tensor([-0.5092, -0.5636])    0      1   \n",
      "tensor([-0.3752, -0.1839])    1      0   \n",
      "tensor([-0.2394, -0.3401])    0      0   \n",
      "tensor([-1.1984, -0.7038])    1      1   \n",
      "tensor([0.1777, 0.1372])      0      1   \n",
      "tensor([0.6252, 0.5988])      0      0   \n",
      "tensor([0.3596, 0.1860])      0      1   \n",
      "tensor([0.5760, 0.6492])      1      1   \n",
      "tensor([-0.2486, -0.1580])    1      0   \n",
      "\n",
      "262 out of 500 = 52.40% correct\n"
     ]
    }
   ],
   "source": [
    "rows = 500\n",
    "correct = 0\n",
    "print(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\n",
    "for i in range(rows):\n",
    "    print(f'{str(y_val[i]):26} {y_val[i].argmax():^7}{y_test[i]:^7}')\n",
    "    if y_val[i].argmax().item() == y_test[i]:\n",
    "        correct += 1\n",
    "print(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "boring-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    a = y_val[i].argmax().item()\n",
    "    y_pred.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "governing-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "available-response",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1805 1820]\n",
      " [ 624  751]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.50      0.60      3625\n",
      "           1       0.29      0.55      0.38      1375\n",
      "\n",
      "    accuracy                           0.51      5000\n",
      "   macro avg       0.52      0.52      0.49      5000\n",
      "weighted avg       0.62      0.51      0.54      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print('\\n')\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-supervisor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-rwanda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
